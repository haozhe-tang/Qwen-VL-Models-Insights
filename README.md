## 概要

Qwen-VLに関する最新の研究や関連情報をまとめたリポジトリです。とくに日本語に関するタスクへの応用を中心に扱っています。

## Qwen-VL関連モデル・派生モデル

---

### olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models

**概要：**

複雑なレイアウトを持つドキュメントでも、正しい読み順でテキストを抽出できるVLMです。

**モデル：** 

Qwen2‑VL‑7B‑Instruct をベースモデルにしています。

**学習データ：**

25万ページ分のPDF画像を用い、GPT‑4oで生成したテキストをラベルとして学習に利用しました。

**学習手法：**

PyPDF を用いて文字ブロックや画像の座標情報を抽出し、{x, y, width, height} 付きのテキストと共にページをレンダリングした画像を入力としてQwen2‑VLをファインチューニングを行います。LoRAとフルパラメータファインチューニング両方実施し、フルパラメータの方が精度が高いとの結果が報告されました。

**感想：**

ドキュメント・アンカリングにより文字情報だけでなくレイアウト情報も学習に取り込むことで、PDF抽出の精度が向上しました。モデル自体の構造変更は行わず、追加情報のみで性能改善を実現しています。ただし、学習ラベルを GPT 生成データに依存しているため、商用利用についてはライセンスや生成データの扱いに注意が必要だと考えます。

実際に日本語ドキュメントで検証したところ、複雑な表組みや細かいレイアウトも正確に抽出できることが確認できました。ただし、日本語 PDF に対する追加学習は行われていないため、文字認識そのものの精度は Qwen2‑VL のベースモデルと大きく変わらない印象です。また、スキャンした PDF には座標情報が含まれないため、こうした非デジタル文書については Qwen2‑VL と同等の性能に留まると理解しています。

---

**OmniSVG: A Unified Scalable Vector Graphics Generation Model**

WIP
