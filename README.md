# Qwen-VL-Models-Insights

# Qwen-VL関連モデル・情報まとめ

## 概要

このリポジトリは、Qwen-VL最新の研究動向や関連情報をまとめることを目的としています。

## Qwen-VL関連モデル

---

### olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models

概要：複雑なレイアウトを持つドキュメントでも、正しい読み順でテキストを抽出できるVLMです。

モデル： Qwen2‑VL‑7B‑Instruct をベースモデルにしています。

学習データ：249,332ページ分のPDF画像を用い、GPT‑4oで生成したテキストをラベルとして学習に利用しました。

学習手法：PyPDF を用いて文字ブロックや画像の座標情報を抽出し、{x, y, width, height} 付きのテキストと共にページをレンダリングした画像を入力としてQwen2‑VLをファインチューニングを行います。LoRAとフルパラメータファインチューニング両方実施し、フルパラメータの方が精度が高いとの結果が報告されました。

感想：ドキュメント・アンカリングにより文字情報だけでなくレイアウト情報も学習に取り込むことで、PDF抽出の精度が向上しました。モデル自体の構造変更は行わず、追加情報のみで性能改善を実現しています。ただし、学習ラベルを GPT 生成データに依存しているため、商用利用についてはライセンスや生成データの扱いに注意が必要だと考えます。
